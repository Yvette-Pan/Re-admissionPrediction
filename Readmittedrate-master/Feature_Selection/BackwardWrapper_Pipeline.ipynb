{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diabetic = pd.read_csv(\"New_train_set.csv\")\n",
    "diabetic_test = pd.read_csv(\"New_test_set.csv\")\n",
    "diabetic = diabetic.drop(diabetic.columns[0],axis = 1)\n",
    "diabetic_test = diabetic_test.drop(diabetic_test.columns[0],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm_col_clf_piper(X_train, y_train, X_test, X_label, parameters, clf, scoring= 'f1'):\n",
    "    \n",
    "    # parameters: dict of parameter need to tune\n",
    "    # clf: classifier\n",
    "    # n_features: number of features want to find, default is half of all features\n",
    "    # scoring: type of score using to tune, default is f1 score\n",
    "    \n",
    "    pipe = make_pipeline(\n",
    "                    (SMOTE()),\n",
    "                    (SFS(clf,\"best\",forward=False,scoring=scoring,cv=5)),\n",
    "                    (clf)\n",
    "                    )\n",
    "    # tune model with different parameters\n",
    "    grid = GridSearchCV(estimator = pipe, param_grid = parameters, cv = 5, n_jobs = -1, verbose = 50, scoring = scoring)\n",
    "    grid.fit(X_train, y_train)\n",
    "    # get the selected feature index \n",
    "    best_pipe = grid.best_estimator_\n",
    "    feature_idx = (best_pipe.named_steps['sequentialfeatureselector'].transform(np.arange(len(X_train.columns)).reshape(1, -1)))[0]\n",
    "    # use best parameter to predict test label\n",
    "    pred = grid.predict(X_test)\n",
    "    \n",
    "    # calculate different score based on prediction\n",
    "    conf = confusion_matrix(X_label,pred)\n",
    "    test_score = {\n",
    "    \"accuracy\":accuracy_score(X_label,pred),\n",
    "    \"precision\":precision_score(X_label,pred,\"binary\"),\n",
    "    \"recall\":recall_score(X_label,pred,\"binary\"),\n",
    "    \"f1_score\":f1_score(X_label,pred,\"binary\"),\n",
    "    \"roc_auc\":roc_auc_score(X_label,pred)\n",
    "    }\n",
    "    return grid.cv_results_['mean_test_score'], grid.best_params_, conf , test_score, feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(name, parameters):\n",
    "    with open(name + '_param.csv', 'w') as f:\n",
    "        for key in parameters.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key, parameters[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 = Perceptron(tol=1e-3, random_state=42)\n",
    "clf3 = RandomForestClassifier(n_estimators='warn', criterion='gini', max_depth=None, \n",
    "                          min_samples_split=2, min_samples_leaf=1, \n",
    "                          min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                          max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                          min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                          n_jobs=None, random_state=None, verbose=0, warm_start=False, \n",
    "                          class_weight=None)\n",
    "clf4_5 = LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=3)\n",
    "clf4 = SVC(verbose=3)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf6 = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logit Tuning Params\n",
    "C = [ 0.01, 0.1, 1, 10, 100] \n",
    "parameters_log = {'logisticregression__C':C}\n",
    "#Percept Tuning Params\n",
    "alpha = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000]\n",
    "parameters_per = {'perceptron__alpha':alpha}\n",
    "#Lin SVM Tunning Params\n",
    "parameters_lin_svm = {'linearsvc__C': C}\n",
    "#SVM tuning Params\n",
    "degree = [1,2]\n",
    "gamma = [.001, .01,]\n",
    "kernel = [\"rbf\",\"poly\"]\n",
    "parameters_svm = {'svc__C':C, 'svc__degree': degree, 'svc__gamma':gamma,'svc__kernel':kernel }\n",
    "#Random Forest Tunning Params\n",
    "c45_param = {'randomforestclassifier__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "#KNN Tuning Params\n",
    "k = [1, 3, 5, 11, 21, 41, 61, 81]\n",
    "parameters_knn = {'kneighborsclassifier__n_neighbors':k}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_score, logit_param, logit_conf, logit_test_score, logit_feature_idx = sm_col_clf_piper(diabetic.iloc[:,:-1],diabetic['y'],diabetic_test.iloc[:,:-1],diabetic_test['y'],parameters_log,clf6)\n",
    "print(\"Train score:\",logit_score)\n",
    "print(\"Tuned parameter:\",logit_param)\n",
    "print(\"Confusion Matrix:\",logit_conf)\n",
    "print(\"Test score:\",logit_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('logit_para', logit_param)\n",
    "write_csv('logit_test_score', logit_test_score)\n",
    "(diabetic.iloc[:,logit_feature_idx]).to_csv(\"logit_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_score, per_param, per_conf, per_test_score, per_feature_idx = sm_col_clf_piper(diabetic.iloc[:,:-1],diabetic['y'],diabetic_test.iloc[:,:-1],diabetic_test['y'],parameters_per,clf2)\n",
    "print(\"Train score:\",per_score)\n",
    "print(\"Tuned parameter:\",per_param)\n",
    "print(\"Confusion Matrix:\",per_conf)\n",
    "print(\"Test score:\",per_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('per_para', per_param)\n",
    "write_csv('per_test_score', per_test_score)\n",
    "(diabetic.iloc[:,per_feature_idx]).to_csv(\"per_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svm_score, lin_svm_param, lin_svm_conf, lin_svm_test_score, lin_svm_feature_idx = sm_col_clf_piper(diabetic.iloc[:,:-1],diabetic['y'],diabetic_test.iloc[:,:-1],diabetic_test['y'],parameters_lin_svm,clf4_5)\n",
    "print(\"Train score:\",lin_svm_score)\n",
    "print(\"Tuned parameter:\",lin_svm_param)\n",
    "print(\"Confusion Matrix:\",lin_svm_conf)\n",
    "print(\"Test score:\",lin_svm_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('lin_svm_para', lin_svm_param)\n",
    "write_csv('lin_svm_test_score', lin_svm_test_score)\n",
    "(diabetic.iloc[:,lin_svm_feature_idx]).to_csv(\"lin_svm_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_score, RF_param, RF_conf, RF_test_score, RF_feature_idx = sm_col_clf_piper(diabetic.iloc[:,:-1],diabetic['y'],diabetic_test.iloc[:,:-1],diabetic_test['y'],c45_param,clf3)\n",
    "print(\"Train score:\",RF_score)\n",
    "print(\"Tuned parameter:\",RF_param)\n",
    "print(\"Confusion Matrix:\",RF_conf)\n",
    "print(\"Test score:\",RF_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('RF_para', RF_param)\n",
    "write_csv('RF_test_score', RF_test_score)\n",
    "(diabetic.iloc[:,RF_feature_idx]).to_csv(\"RF_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score, knn_param, knn_conf, knn_test_score, knn_feature_idx = sm_col_clf_piper(diabetic.iloc[:,:-1],diabetic['y'],diabetic_test.iloc[:,:-1],diabetic_test['y'],parameters_knn,clf5)\n",
    "print(\"Train score:\",knn_score)\n",
    "print(\"Tuned parameter:\",knn_param)\n",
    "print(\"Confusion Matrix:\",knn_conf)\n",
    "print(\"Test score:\",knn_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('knn_para', knn_param)\n",
    "write_csv('knn_test_score', knn_test_score)\n",
    "(diabetic.iloc[:,knn_feature_idx]).to_csv(\"knn_feature.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

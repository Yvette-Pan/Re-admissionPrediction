{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diabetic = pd.read_csv(\"New_train_set.csv\")\n",
    "diabetic = diabetic.drop(diabetic.columns[0],axis = 1)\n",
    "\n",
    "sample = pd.read_csv(\"sample_diabetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def wrapper(clf,X_raw,y,k,n_bag):\n",
    "    X = X_raw.copy()\n",
    "    Wrap_accuracy_old = 0\n",
    "    Wrap_accuracy_new = 0.00001\n",
    "    n = 0\n",
    "    #generate an empty dataframe to save features\n",
    "    Wrap_filt = X.iloc[:,[0,1]]\n",
    "    Wrap_filt = Wrap_filt.drop(Wrap_filt.columns[[0,1]],axis=1)\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state=42, shuffle=False)\n",
    "    rus = RandomUnderSampler(replacement=True)\n",
    "    \n",
    "    while(Wrap_accuracy_old <  Wrap_accuracy_new):\n",
    "        Wrap_accuracy_old = Wrap_accuracy_new\n",
    "        avg_accuracies_list = []\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            accur_list = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                y_Pred = []\n",
    "                for j in range(n_bag):\n",
    "                    # sample N balanced bag to do N times of prediction\n",
    "                    X_res, y_res = rus.fit_resample(Wrap_filt.join(X.iloc[:,i]).iloc[train_index,:], y.iloc[train_index])\n",
    "                    clf.fit(X_res, y_res)\n",
    "                    y_pred = clf.predict(Wrap_filt.join(X.iloc[:,i]).iloc[test_index,:])\n",
    "                    y_Pred.append(y_pred)\n",
    "                # turning list of prediction in to ndarray\n",
    "                y_Pred = np.array(y_Pred)\n",
    "                # majority vote using N prediction\n",
    "                Y_Pred=[]\n",
    "                for j in range(y_Pred.shape[1]):\n",
    "                    Y_Pred.append((Counter(y_Pred[:,j]).most_common())[0][0])\n",
    "                Y_Pred = np.array(Y_Pred)\n",
    "                # use result of majority vote to calculate score\n",
    "                score = f1_score(y.iloc[test_index],Y_Pred,average = \"weighted\")\n",
    "                accur_list.append(score)\n",
    "            avg_accuracies_list.append(np.mean(accur_list))\n",
    "            \n",
    "        # add the highest accuracy feature to the selected dataframe\n",
    "        Wrap_filt = Wrap_filt.join(X.iloc[:,np.argsort(avg_accuracies_list)[-1]])\n",
    "        # drop the selected feature from the unselected dataframe\n",
    "        X = X.drop(X.columns[np.argsort(avg_accuracies_list)[-1]],axis=1)\n",
    "        # renew the accuracy\n",
    "        Wrap_accuracy_new = np.sort(avg_accuracies_list)[-1]                 \n",
    "        print(n,\"selection is done\")\n",
    "        n = n + 1\n",
    "    return Wrap_accuracy_old,n-1,Wrap_filt.drop(Wrap_filt.columns[-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 = Perceptron(random_state=42, n_jobs=-1)\n",
    "clf3 = RandomForestClassifier(n_estimators='warn',n_jobs=-1)\n",
    "clf4 = LinearSVC()\n",
    "clf5 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf6 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_acc, logit_num_feature, logit_features = wrapper(clf6,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_features.to_csv(\"Logit_Forward_Bagging.csv\",index=False)\n",
    "logit_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc, NB_num_feature, NB_features = wrapper(clf1,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_features.to_csv(\"NB_Forward_Bagging.csv\",index=False)\n",
    "NB_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Per_acc, Per_num_feature, Per_features = wrapper(clf2,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Per_features.to_csv(\"Per_Forward_Bagging.csv\",index=False)\n",
    "Per_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_acc, RF_num_feature, RF_features = wrapper(clf3,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_features.to_csv(\"RF_Forward_Bagging.csv\",index=False)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc, SVM_num_feature, SVM_features = wrapper(clf4,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_features.to_csv(\"SVM_Forward_Bagging.csv\",index=False)\n",
    "SVM_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc, knn_num_feature, knn_features = wrapper(clf5,diabetic.iloc[:,:-1],diabetic.iloc[:,-1],5,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_features.to_csv(\"knn_Forward_Bagging.csv\",index=False)\n",
    "knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = ['NB',\"Perceptron\",\"RF\",\"SVM\",\"KNN\",\"Logit\"]\n",
    "summary_acc = pd.DataFrame({\"accuracy\":[NB_acc,Per_acc,RF_acc,SVM_acc,knn_acc,logit_acc]},index=modelname)\n",
    "summary_acc.to_csv(\"Accuracy_Forward_Bagging.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
